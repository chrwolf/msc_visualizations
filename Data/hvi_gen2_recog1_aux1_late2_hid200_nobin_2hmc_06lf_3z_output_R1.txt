(50000L, 784L)
compiled score function
garray(152.78314208984375)
Compiled loss functions
0 0.0 143.858291626
1 0.0 144.115539551
2 0.0 144.013244629
3 0.0 144.228302002
4 0.0 144.440582275
5 0.0 144.64465332
6 0.0 144.467910767
7 0.0 144.511047363
8 0.0 144.406967163
9 0.0 144.280578613
10 0.0 144.417678833
11 0.0 144.099151611
12 0.0 144.214889526
13 0.0 144.127426147
14 0.0 144.098449707
15 0.0 144.234161377
16 0.0 144.208740234
17 0.0 144.071853638
18 0.0 143.969497681
19 0.0 144.261001587
20 0.0 143.942001343
21 0.0 144.091369629
22 0.0 143.679489136
23 0.0 144.025741577
24 0.0 143.94821167
25 0.0 143.888122559
26 0.0 143.791320801
27 0.0 144.184402466
28 0.0 143.930770874
29 0.0 143.80897522
30 0.0 143.711898804
31 0.0 143.798416138
32 0.0 143.85508728
33 0.0 143.792999268
34 0.0 143.740493774
35 0.0 143.800994873
36 0.0 143.896636963
37 0.0 143.832443237
38 0.0 143.723342896
39 0.0 143.700439453
40 0.0 143.693771362
41 0.0 143.686126709
42 0.0 143.788497925
43 0.0 143.811553955
44 0.0 143.684020996
45 0.0 143.615356445
46 0.0 143.520721436
47 0.0 143.488052368
48 0.0 143.935119629
49 0.0 143.874038696
50 0.0 143.710189819
51 0.0 143.456130981
52 0.0 143.735397339
53 0.0 143.654998779
54 0.0 143.664245605
55 0.0 143.565155029
56 0.0 143.654602051
57 0.0 143.730102539
58 0.0 143.435424805
59 0.0 143.706436157
60 0.0 143.454147339
61 0.0 143.907180786
62 0.0 143.560882568
63 0.0 143.467391968
64 0.0 143.477676392
65 0.0 143.437988281
66 0.0 143.269866943
67 0.0 143.686096191
68 0.0 143.557006836
69 0.0 143.282226562
70 0.0 143.479293823
71 0.0 143.285476685
72 0.0 143.681594849
73 0.0 143.485443115
74 0.0 143.314117432
75 0.0 143.501556396
76 0.0 143.35005188
77 0.0 143.253234863
78 0.0 143.459335327
79 0.0 143.392379761
80 0.0 143.25402832
81 0.0 143.466522217
82 0.0 143.106185913
83 0.0 143.408370972
84 0.0 143.31803894
85 0.0 143.332199097
86 0.0 143.174728394
87 0.0 143.533218384
88 0.0 143.479873657
89 0.0 143.317626953
90 0.0 143.262405396
91 0.0 143.306259155
92 0.0 143.413391113
93 0.0 143.339324951
94 0.0 143.482620239
95 0.0 143.253921509
96 0.0 143.173522949
97 0.0 143.326644897
98 0.0 143.226699829
99 0.0 143.240539551
100 0.0 143.204452515
101 0.0 143.052078247
102 0.0 143.272888184
103 0.0 143.268600464
104 0.0 143.282363892
105 0.0 143.671020508
106 0.0 143.357574463
107 0.0 143.100997925
108 0.0 143.223876953
109 0.0 143.163360596
110 0.0 143.093444824
111 0.0 143.148117065
112 0.0 143.019378662
113 0.0 143.062896729
114 0.0 143.044265747
115 0.0 143.238021851
116 0.0 142.952789307
117 0.0 143.003997803
118 0.0 143.152984619
119 0.0 143.120574951
120 0.0 143.112701416
121 0.0 143.000732422
122 0.0 142.985824585
123 0.0 143.138519287
124 0.0 142.915222168
125 0.0 143.205001831
126 0.0 143.034790039
127 0.0 143.415878296
128 0.0 142.986709595
129 0.0 143.174285889
130 0.0 142.961715698
131 0.0 142.891616821
132 0.0 143.036972046
133 0.0 142.953704834
134 0.0 142.951919556
135 0.0 143.018890381
136 0.0 142.693115234
137 0.0 143.150985718
138 0.0 143.326065063
139 0.0 142.928100586
140 0.0 142.893310547
141 0.0 142.956802368
142 0.0 142.994903564
143 0.0 142.954971313
144 0.0 143.052627563
145 0.0 143.017349243
146 0.0 142.870162964
147 0.0 142.799804688
148 0.0 142.912826538
149 0.0 143.063903809
150 0.0 143.081588745
151 0.0 142.854614258
152 0.0 142.708511353
153 0.0 142.930557251
154 0.0 142.855636597
155 0.0 142.920471191
156 0.0 142.836212158
157 0.0 143.033752441
158 0.0 142.823074341
159 0.0 142.794433594
160 0.0 142.875518799
161 0.0 142.869827271
162 0.0 142.970245361
163 0.0 142.801223755
164 0.0 142.85987854
165 0.0 142.9659729
166 0.0 143.030715942
167 0.0 142.734268188
168 0.0 142.775024414
169 0.0 143.018920898
170 0.0 142.972045898
171 0.0 142.906402588
172 0.0 142.79864502
173 0.0 142.707366943
174 0.0 142.974746704
175 0.0 142.793304443
176 0.0 142.784729004
177 0.0 142.688339233
178 0.0 143.300216675
179 0.0 143.059997559
180 0.0 142.826065063
181 0.0 142.662414551
182 0.0 142.759796143
183 0.0 142.689575195
184 0.0 142.910568237
185 0.0 142.928207397
186 0.0 142.731170654
187 0.0 143.000366211
188 0.0 143.212142944
189 0.0 142.657196045
190 0.0 142.831802368
191 0.0 142.862426758
192 0.0 142.691864014
193 0.0 142.642364502
194 0.0 142.58291626
195 0.0 142.800109863
196 0.0 142.866363525
197 0.0 142.560882568
198 0.0 142.843002319
199 0.0 142.730026245
200 0.0 142.769973755
201 0.0 142.644943237
202 0.0 142.627365112
203 0.0 142.70690918
204 0.0 142.731765747
205 0.0 142.802566528
206 0.0 142.75769043
207 0.0 142.721878052
208 0.0 142.706222534
209 0.0 142.4609375
210 0.0 142.756546021
211 0.0 142.637374878
212 0.0 142.591308594
213 0.0 142.494567871
214 0.0 142.648040771
215 0.0 142.576828003
216 0.0 142.650726318
217 0.0 142.689376831
218 0.0 142.827713013
219 0.0 142.63319397
220 0.0 142.682678223
221 0.0 142.745223999
222 0.0 142.824539185
223 0.0 142.884643555
224 0.0 142.710067749
225 0.0 142.728775024
226 0.0 142.606689453
227 0.0 142.903045654
228 0.0 142.627319336
229 0.0 142.55090332
230 0.0 142.74848938
231 0.0 142.630447388
232 0.0 142.634262085
233 0.0 142.589767456
234 0.0 142.828369141
235 0.0 142.881225586
236 0.0 142.793045044
237 0.0 142.625549316
238 0.0 142.380889893
239 0.0 142.777877808
240 0.0 142.546783447
241 0.0 142.811096191
242 0.0 142.680084229
243 0.0 142.544052124
244 0.0 142.628097534
245 0.0 142.431594849
246 0.0 142.580352783
247 0.0 142.826416016
248 0.0 142.723815918
249 0.0 142.696517944
creating pickled numpy output
wrote pickled numpy output
Final validation loss
garray(142.54978942871094)
Final test loss
garray(143.88369750976562)
Theano: Initializing cuBLAS
