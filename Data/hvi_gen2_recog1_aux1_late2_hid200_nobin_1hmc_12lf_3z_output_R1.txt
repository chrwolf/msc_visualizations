(50000L, 784L)
compiled score function
garray(153.68226623535156)
Compiled loss functions
0 0.0 144.517593384
1 0.0 144.194976807
2 0.0 144.369720459
3 0.0 144.59262085
4 0.0 144.837356567
5 0.0 145.042404175
6 0.0 144.913589478
7 0.0 144.918029785
8 0.0 145.072341919
9 0.0 145.046508789
10 0.0 145.050064087
11 0.0 144.856292725
12 0.0 144.890167236
13 0.0 144.923294067
14 0.0 144.783172607
15 0.0 144.875488281
16 0.0 144.961380005
17 0.0 144.978973389
18 0.0 144.866424561
19 0.0 144.834365845
20 0.0 144.81262207
21 0.0 144.770431519
22 0.0 144.84614563
23 0.0 144.753845215
24 0.0 144.763961792
25 0.0 144.958206177
26 0.0 144.775115967
27 0.0 144.81350708
28 0.0 144.700698853
29 0.0 144.774627686
30 0.0 144.694366455
31 0.0 144.925521851
32 0.0 144.762817383
33 0.0 144.713088989
34 0.0 144.59513855
35 0.0 144.68081665
36 0.0 144.854492188
37 0.0 144.861663818
38 0.0 144.619903564
39 0.0 144.666015625
40 0.0 144.823318481
41 0.0 144.768966675
42 0.0 144.690643311
43 0.0 145.038970947
44 0.0 144.689651489
45 0.0 144.947921753
46 0.0 144.861099243
47 0.0 144.546295166
48 0.0 144.84022522
49 0.0 144.557876587
50 0.0 144.7290802
51 0.0 144.722900391
52 0.0 144.594421387
53 0.0 144.557312012
54 0.0 144.624542236
55 0.0 144.658233643
56 0.0 144.666183472
57 0.0 144.758850098
58 0.0 144.496643066
59 0.0 144.774368286
60 0.0 144.759643555
61 0.0 144.449996948
62 0.0 144.712310791
63 0.0 144.691589355
64 0.0 144.535232544
65 0.0 144.705566406
66 0.0 144.491088867
67 0.0 144.568740845
68 0.0 144.552215576
69 0.0 144.376739502
70 0.0 144.550003052
71 0.0 144.653366089
72 0.0 144.589447021
73 0.0 144.483093262
74 0.0 144.545288086
75 0.0 144.657852173
76 0.0 144.640853882
77 0.0 144.41178894
78 0.0 144.572753906
79 0.0 144.708892822
80 0.0 144.472869873
81 0.0 144.236022949
82 0.0 144.46647644
83 0.0 144.821151733
84 0.0 144.302703857
85 0.0 144.624511719
86 0.0 144.638519287
87 0.0 144.486663818
88 0.0 144.555465698
89 0.0 144.494750977
90 0.0 144.507095337
91 0.0 144.620910645
92 0.0 144.6693573
93 0.0 144.571014404
94 0.0 144.771896362
95 0.0 144.416351318
96 0.0 144.541748047
97 0.0 144.535690308
98 0.0 144.519973755
99 0.0 144.737365723
100 0.0 144.550048828
101 0.0 144.588790894
102 0.0 144.52166748
103 0.0 144.68107605
104 0.0 144.576889038
105 0.0 144.557479858
106 0.0 144.851470947
107 0.0 144.709503174
108 0.0 144.697174072
109 0.0 144.658493042
110 0.0 144.542373657
111 0.0 144.853057861
112 0.0 144.617401123
113 0.0 144.563156128
114 0.0 144.537902832
115 0.0 144.753662109
116 0.0 144.870101929
117 0.0 144.974960327
118 0.0 144.923339844
119 0.0 144.926177979
120 0.0 144.624298096
121 0.0 145.041275024
122 0.0 145.059341431
123 0.0 145.234725952
124 0.0 145.333908081
125 0.0 145.354919434
126 0.0 145.630157471
127 0.0 145.886871338
128 0.0 145.890304565
129 0.0 145.951599121
130 0.0 145.455764771
131 0.0 145.806045532
132 0.0 145.92276001
133 0.0 145.848327637
134 0.0 145.751739502
135 0.0 145.987442017
136 0.0 145.480270386
137 0.0 145.85597229
138 0.0 145.7137146
139 0.0 145.972747803
140 0.0 146.088012695
141 0.0 146.036743164
142 0.0 146.034378052
143 0.0 145.879852295
144 0.0 146.445465088
145 0.0 145.945953369
146 0.0 145.907577515
147 0.0 146.196044922
148 0.0 146.193252563
149 0.0 146.480377197
150 0.0 146.284362793
151 0.0 146.005325317
152 0.0 145.975128174
153 0.0 146.117919922
154 0.0 146.157867432
155 0.0 145.755691528
156 0.0 146.298614502
157 0.0 146.291061401
158 0.0 145.951477051
159 0.0 146.426391602
160 0.0 146.041091919
161 0.0 146.404052734
162 0.0 146.103103638
163 0.0 146.219818115
164 0.0 146.136123657
165 0.0 146.073440552
166 0.0 146.177597046
167 0.0 146.036239624
168 0.0 145.83757019
169 0.0 146.270492554
170 0.0 146.111999512
171 0.0 146.228546143
172 0.0 146.08152771
173 0.0 145.996490479
174 0.0 146.147720337
175 0.0 145.834991455
176 0.0 146.158401489
177 0.0 146.212768555
178 0.0 146.422470093
179 0.0 146.556213379
180 0.0 146.163696289
181 0.0 146.282394409
182 0.0 146.36505127
183 0.0 146.315551758
184 0.0 146.713394165
185 0.0 146.646972656
186 0.0 146.572570801
187 0.0 147.009216309
188 0.0 147.048706055
189 0.0 147.02192688
190 0.0 147.244903564
191 0.0 147.465652466
192 0.0 147.383605957
193 0.0 147.628814697
194 0.0 147.728622437
195 0.0 147.591125488
196 0.0 147.521621704
197 0.0 147.457748413
198 0.0 147.575775146
199 0.0 147.692367554
200 0.0 147.836639404
201 0.0 147.870407104
202 0.0 147.913818359
203 0.0 148.131652832
204 0.0 148.537353516
205 0.0 148.559326172
206 0.0 148.387756348
207 0.0 148.398727417
208 0.0 148.349838257
209 0.0 148.555755615
210 0.0 148.875396729
211 0.0 148.682952881
212 0.0 148.755020142
213 0.0 148.888290405
214 0.0 149.148391724
215 0.0 148.977706909
216 0.0 148.940292358
217 0.0 149.063278198
218 0.0 149.078125
219 0.0 149.092315674
220 0.0 149.558776855
221 0.0 149.069137573
222 0.0 149.206359863
223 0.0 148.935028076
224 0.0 149.075500488
225 0.0 149.201644897
226 0.0 148.960617065
227 0.0 148.90335083
228 0.0 149.16746521
229 0.0 149.221755981
230 0.0 149.195297241
231 0.0 148.929290771
232 0.0 149.373001099
233 0.0 149.318252563
234 0.0 149.387039185
235 0.0 149.411346436
236 0.0 149.454544067
237 0.0 149.401947021
238 0.0 149.343887329
239 0.0 149.300338745
240 0.0 149.219299316
241 0.0 149.281661987
242 0.0 149.215621948
243 0.0 149.147293091
244 0.0 149.365997314
245 0.0 149.124053955
246 0.0 149.285842896
247 0.0 149.159194946
248 0.0 148.749816895
249 0.0 148.740859985
creating pickled numpy output
wrote pickled numpy output
Final validation loss
garray(144.2065887451172)
Final test loss
garray(145.70689392089844)
Theano: Initializing cuBLAS
