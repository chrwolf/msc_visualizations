(50000L, 784L)
compiled score function
Old best loss:
garray(128.08509826660156)
Compiled loss functions
[321988, 326885, 326959, 354695, 354815, 354826, 354827, 354835, 354899, 354914, 354934, 354971, 354983, 354995, 355123, 355135, 355174, 355230, 355287, 355327, 355391]

0 0.0 128.082077026 [ 0.00625503]
1 0.0 128.194976807 [ 0.00626428]
2 0.0 128.12651062 [ 0.00627168]
3 0.0 128.100112915 [ 0.00626708]
4 0.0 128.148757935 [ 0.00628528]
5 0.0 128.156829834 [ 0.00627772]
6 0.0 128.018554688 [ 0.00626697]
7 0.0 128.046295166 [ 0.00626754]
8 0.0 128.095657349 [ 0.00630685]
9 0.0 128.051528931 [ 0.00630363]
10 0.0 128.155715942 [ 0.00630315]
11 0.0 128.080123901 [ 0.00630194]
12 0.0 128.044372559 [ 0.00630807]
13 0.0 128.092941284 [ 0.00630247]
14 0.0 128.109191895 [ 0.00630065]
15 0.0 128.064453125 [ 0.00630343]
16 0.0 128.074859619 [ 0.00630163]
17 0.0 128.099243164 [ 0.00629644]
18 0.0 128.088851929 [ 0.00629343]
19 0.0 128.071533203 [ 0.00629355]
20 0.0 128.073974609 [ 0.0063248]
21 0.0 128.124481201 [ 0.00632144]
22 0.0 128.085754395 [ 0.00631995]
23 0.0 128.079421997 [ 0.00632413]
24 0.0 128.07144165 [ 0.00632446]
25 0.0 128.206039429 [ 0.00634658]
26 0.0 128.10899353 [ 0.00633628]
27 0.0 128.038070679 [ 0.00633674]
28 0.0 128.11315918 [ 0.00633432]
29 0.0 128.128372192 [ 0.00633015]
30 0.0 128.084732056 [ 0.00633321]
31 0.0 128.095657349 [ 0.00632112]
32 0.0 128.109283447 [ 0.00632774]
33 0.0 128.082000732 [ 0.00629781]
34 0.0 128.136932373 [ 0.00630168]
35 0.0 128.084579468 [ 0.00630588]
36 0.0 128.188995361 [ 0.00630914]
37 0.0 128.15802002 [ 0.00630761]
38 0.0 128.134963989 [ 0.00629815]
39 0.0 128.098297119 [ 0.00629558]
40 0.0 128.160095215 [ 0.00629208]
41 0.0 128.139633179 [ 0.00629379]
42 0.0 128.066558838 [ 0.00630015]
43 0.0 128.116760254 [ 0.00629638]
44 0.0 128.218505859 [ 0.00629266]
45 0.0 128.105926514 [ 0.00628945]
46 0.0 128.09387207 [ 0.00628798]
47 0.0 128.130371094 [ 0.00628723]
48 0.0 128.132003784 [ 0.00630313]
49 0.0 128.111480713 [ 0.00628564]
50 0.0 128.096679688 [ 0.00629069]
51 0.0 128.053359985 [ 0.00629228]
52 0.0 128.144073486 [ 0.00628734]
53 0.0 128.097213745 [ 0.00628211]
54 0.0 128.074890137 [ 0.0062909]
55 0.0 128.132003784 [ 0.00627874]
56 0.0 128.083984375 [ 0.00628132]
57 0.0 128.142532349 [ 0.00627836]
58 0.0 128.106643677 [ 0.00628625]
59 0.0 128.0962677 [ 0.00628325]
60 0.0 128.109558105 [ 0.00628197]
61 0.0 128.089035034 [ 0.00628335]
62 0.0 128.105484009 [ 0.00628142]
63 0.0 128.098739624 [ 0.00628202]
64 0.0 128.216491699 [ 0.00627655]
65 0.0 128.065338135 [ 0.00628279]
66 0.0 128.048233032 [ 0.00626754]
67 0.0 128.149581909 [ 0.00625886]
68 0.0 128.070983887 [ 0.0062591]
69 0.0 128.554992676 [ 0.00622011]
70 0.0 128.305099487 [ 0.00618038]
71 0.0 128.142944336 [ 0.00618099]
72 0.0 128.15020752 [ 0.00618098]
73 0.0 128.078155518 [ 0.00618178]
74 0.0 128.088134766 [ 0.00618162]
75 0.0 128.074676514 [ 0.00618215]
76 0.0 128.083343506 [ 0.00618235]
77 0.0 128.076293945 [ 0.00618247]
78 0.0 128.107467651 [ 0.00618194]
79 0.0 128.072616577 [ 0.00618221]
80 0.0 128.148590088 [ 0.00618184]
81 0.0 128.103118896 [ 0.0061827]
82 0.0 128.08782959 [ 0.00618165]
83 0.0 128.096130371 [ 0.00618262]
84 0.0 128.126831055 [ 0.00618262]
85 0.0 128.078430176 [ 0.00618243]
86 0.0 128.160202026 [ 0.00618318]
87 0.0 128.119720459 [ 0.00618379]
88 0.0 128.087417603 [ 0.00618358]
89 0.0 128.102539062 [ 0.00618374]
90 0.0 128.068161011 [ 0.00618348]
91 0.0 128.060150146 [ 0.00618393]
92 0.0 128.064498901 [ 0.00618508]
93 0.0 128.105422974 [ 0.00618527]
94 0.0 128.075119019 [ 0.00618562]
95 0.0 128.108276367 [ 0.00618482]
96 0.0 128.062973022 [ 0.0061846]
97 0.0 128.062698364 [ 0.00618648]
98 0.0 128.060455322 [ 0.00618666]
99 0.0 128.079833984 [ 0.00618713]
100 0.0 128.110229492 [ 0.00618775]
101 0.0 128.119491577 [ 0.0061878]
102 0.0 128.108139038 [ 0.00618846]
103 0.0 128.069458008 [ 0.00618796]
104 0.0 128.143310547 [ 0.00618842]
105 0.0 128.067138672 [ 0.00618853]
106 0.0 128.096862793 [ 0.0061886]
107 0.0 128.053222656 [ 0.00618925]
108 0.0 128.076828003 [ 0.00619098]
109 0.0 128.082000732 [ 0.00617288]
110 0.0 128.259399414 [ 0.00613541]
111 0.0 128.185440063 [ 0.00614076]
112 0.0 128.087387085 [ 0.00614254]
113 0.0 128.167129517 [ 0.00614143]
114 0.0 128.16645813 [ 0.00614324]
115 0.0 128.174453735 [ 0.00614385]
116 0.0 128.100570679 [ 0.00614675]
117 0.0 128.183670044 [ 0.00614743]
118 0.0 128.142868042 [ 0.00614762]
119 0.0 128.227294922 [ 0.00614168]
120 0.0 128.181793213 [ 0.00614148]
121 0.0 128.117782593 [ 0.00614137]
122 0.0 128.131011963 [ 0.0061436]
123 0.0 128.527145386 [ 0.00615899]
124 0.0 128.195144653 [ 0.00615992]
125 0.0 128.134872437 [ 0.00615925]
126 0.0 128.115951538 [ 0.00616181]
127 0.0 128.145019531 [ 0.0061561]
128 0.0 128.140731812 [ 0.0061603]
129 0.0 128.106658936 [ 0.00616521]
130 0.0 128.165023804 [ 0.00615367]
131 0.0 128.121139526 [ 0.00616554]
132 0.0 128.123672485 [ 0.00616301]
133 0.0 128.086456299 [ 0.00616316]
134 0.0 128.134414673 [ 0.00616432]
135 0.0 128.106231689 [ 0.00616477]
136 0.0 128.07800293 [ 0.00616242]
137 0.0 128.08505249 [ 0.00616212]
138 0.0 128.135101318 [ 0.00617175]
139 0.0 128.111679077 [ 0.00617956]
140 0.0 128.110778809 [ 0.00617718]
141 0.0 128.771682739 [ 0.00625398]
142 0.0 128.487701416 [ 0.0062543]
143 0.0 128.34147644 [ 0.00625391]
144 0.0 128.334579468 [ 0.00625371]
145 0.0 128.272354126 [ 0.00625341]
146 0.0 128.292648315 [ 0.00625325]
147 0.0 128.257156372 [ 0.00625323]
148 0.0 128.195907593 [ 0.006253]
149 0.0 128.216674805 [ 0.00625329]
150 0.0 128.164489746 [ 0.00625299]
151 0.0 128.212799072 [ 0.00625282]
152 0.0 128.1925354 [ 0.00625268]
153 0.0 128.1743927 [ 0.00625246]
154 0.0 128.193023682 [ 0.00625251]
155 0.0 128.177001953 [ 0.00625223]
156 0.0 128.182937622 [ 0.00625227]
157 0.0 128.176239014 [ 0.00625215]
158 0.0 128.120300293 [ 0.00625196]
159 0.0 128.15296936 [ 0.00625212]
160 0.0 128.151473999 [ 0.00625182]
161 0.0 128.173080444 [ 0.00625171]
162 0.0 128.220031738 [ 0.00625154]
163 0.0 128.226623535 [ 0.00625104]
164 0.0 128.193664551 [ 0.0062511]
165 0.0 128.24269104 [ 0.00625058]
166 0.0 128.219619751 [ 0.00625046]
167 0.0 128.149795532 [ 0.00625039]
168 0.0 128.161712646 [ 0.00625038]
169 0.0 128.097763062 [ 0.00625038]
170 0.0 128.225067139 [ 0.00625054]
171 0.0 128.17829895 [ 0.00625063]
172 0.0 128.129318237 [ 0.00625066]
173 0.0 128.18309021 [ 0.00625049]
174 0.0 128.139770508 [ 0.0062505]
175 0.0 128.146789551 [ 0.00624997]
176 0.0 128.305496216 [ 0.00625666]
177 0.0 128.191513062 [ 0.00625665]
178 0.0 128.180496216 [ 0.00625662]
179 0.0 128.222320557 [ 0.00625693]
180 0.0 128.144271851 [ 0.00625616]
181 0.0 128.160583496 [ 0.00625617]
182 0.0 128.117034912 [ 0.00625543]
183 0.0 128.169967651 [ 0.0062551]
184 0.0 128.127578735 [ 0.00625526]
185 0.0 128.207092285 [ 0.00624937]
186 0.0 128.249603271 [ 0.00624751]
187 0.0 128.150772095 [ 0.0062489]
188 0.0 128.144073486 [ 0.00624989]
189 0.0 128.121185303 [ 0.0062495]
190 0.0 128.078277588 [ 0.00624934]
191 0.0 128.157974243 [ 0.00624213]
192 0.0 128.132263184 [ 0.00624404]
193 0.0 128.280441284 [ 0.00622655]
194 0.0 128.152420044 [ 0.00622917]
195 0.0 128.210968018 [ 0.00622962]
196 0.0 128.160095215 [ 0.00622946]
197 0.0 128.166717529 [ 0.00623041]
198 0.0 128.125900269 [ 0.00623088]
199 0.0 128.084472656 [ 0.00623196]
creating pickled numpy output
wrote pickled numpy output
Final validation loss
garray(128.08212280273438)
Final test loss
garray(128.9637451171875)
Final estimated test NLL (5000)
126.940496529
Theano: Initializing cuBLAS
